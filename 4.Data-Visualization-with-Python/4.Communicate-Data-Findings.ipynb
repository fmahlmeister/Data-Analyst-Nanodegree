{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Communicate Data Findings\n",
    "\n",
    "SÃ£o Paulo, 15 June of 2019<br>\n",
    "Felipe Mahlmeister\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Summary](#summary)<br>\n",
    "2. [Data Wrangling](#data_wrangling)<br>\n",
    "2.1. [Extracting the Data](#extract)<br>\n",
    "2.2. [Preliminary Wrangling](#preliminary_wrangling)<br>\n",
    "2.3. [Assess](#assess)<br>\n",
    "2.4. [Clean](#clean)<br>\n",
    "4. [Analysis, Modeling, and Validation](#analysis)<br>\n",
    "5. [Conclusion](#conclusion)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## 1. Summary\n",
    "\n",
    "#### intro\n",
    "The data consists of flight arrival and departure details for all commercial flights within the USA, from October 1987 to April 2008. This is a large dataset: there are nearly 120 million records in total, and takes up 1.6 gigabytes of space compressed and 12 gigabytes when uncompressed.\n",
    "\n",
    "These files were downloaded at: http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "#### Objective\n",
    "\n",
    "1. We're going to explore which is the airport with the highest traffic\n",
    "2. How much the traffic increased over the years? Let's check it out with a trending line over the years\n",
    "3. Which are the most used routes? Let's look at the most used routes with routes drawn on a graph of the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_wrangling'></a>\n",
    "## 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all default packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "# from urllib.request import urlretrieve\n",
    "# import glob\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas.api.types import union_categoricals\n",
    "import time\n",
    "\n",
    "# import my packages\n",
    "# packages to get flights data\n",
    "# from jupyterworkflow.data import get_url\n",
    "# from jupyterworkflow.data import get_download_and_unzip\n",
    "# from jupyterworkflow.data import get_flights_data\n",
    "\n",
    "# packages to wrangle data\n",
    "# from jupyterworkflow.data import get_column_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extract'></a>\n",
    "### 2.1. Extracting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the range of years you want to download\n",
    "start_year = 1987\n",
    "last_year = 2008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve reproducibility of this project, the below packages download the files from [stat-computing.org](http://stat-computing.org/dataexpo/2009/the-data.html) according to `start_year` and `last_year` automatically, it also unzip these files in source folder.\n",
    "\n",
    "Package codes in: `jupyterworkflow/data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url, filepath = get_url(start_year, last_year)\n",
    "get_flights_data(url, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preliminary_wrangling'></a>\n",
    "### 2.2. Preliminary Wrangling\n",
    "\n",
    "Before we began to import all csv files to dataframes, first we need to know if it can be imported in a regular workspace.\n",
    "Let's import the last year file (`2008.csv`) and take a look how much memory it requires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('source/2008.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Only this dataframe requires 3.0 GB of memory !</b><br>\n",
    "Considering that we have 22 csv files with almost the same amount of required memory, it's almost impossible to open them on a regular workspace.\n",
    "\n",
    "To analysis the whole years' range, we need a better approach than just simply import all these files as we did on the last code line.\n",
    "\n",
    "We'll take the following strategy (we'll use `2008.csv` as a model):\n",
    "\n",
    "1. Analyze whether we need all columns or if we could delete some of them\n",
    "2. Analyze whether pandas imported the correct data formats and correct inaccurate variable formats.\n",
    "3. Analyze if we could improve the data formats in order to reduce its memory space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "### 2.3. Assess\n",
    "\n",
    "At this assess section, we'll only documentate the changes that we'll make on section 2.4.Clean.\n",
    "\n",
    "#### <div align='center'>Variable descriptions according to [stat-computing.org](http://stat-computing.org/dataexpo/2009/the-data.html)</div>\n",
    "\n",
    "| &nbsp; | Name | Description |\n",
    "| ------ | ---- | ----------- |\n",
    "| 1 | Year | 1987-2008 |\n",
    "| 2 | Month | 1-12 |\n",
    "| 3 | DayofMonth | 1-31 |\n",
    "| 4 | DayOfWeek | 1 (Monday) - 7 (Sunday) |\n",
    "| 5 | DepTime | actual departure time (local, hhmm) |\n",
    "| 6 | CRSDepTime | scheduled departure time (local, hhmm) |\n",
    "| 7 | ArrTime | actual arrival time (local, hhmm) |\n",
    "| 8 | CRSArrTime | scheduled arrival time (local, hhmm) |\n",
    "| 9 | UniqueCarrier | unique carrier code |\n",
    "| 10 | FlightNum | flight number |\n",
    "| 11 | TailNum | plane tail number |\n",
    "| 12 | ActualElapsedTime | in minutes |\n",
    "| 13 | CRSElapsedTime | in minutes |\n",
    "| 14 | AirTime | in minutes |\n",
    "| 15 | ArrDelay | arrival delay, in minutes |\n",
    "| 16 | DepDelay | departure delay, in minutes |\n",
    "| 17 | Origin | origin IATA airport code |\n",
    "| 18 | Dest | destination IATA airport code |\n",
    "| 19 | Distance | in miles |\n",
    "| 20 | TaxiIn | taxi in time, in minutes |\n",
    "| 21 | TaxiOut | taxi out time in minutes |\n",
    "| 22 | Cancelled | was the flight cancelled? |\n",
    "| 23 | CancellationCode | reason for cancellation (A = carrier, B = weather, C = NAS, D = security) |\n",
    "| 24 | Diverted | 1 = yes, 0 = no |\n",
    "| 25 | CarrierDelay | in minutes |\n",
    "| 26 | WeatherDelay | in minutes |\n",
    "| 27 | NASDelay | in minutes |\n",
    "| 28 | SecurityDelay | in minutes |\n",
    "| 29 | LateAircraftDelay | in minutes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Analyze whether we need all columns or if we could delete some of them\n",
    "\n",
    "After analyzing variable descriptions, all variables are relevant for our analysis and none will not be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Analyze whether pandas imported the correct data formats and correct inaccurate variable formats.\n",
    "\n",
    "After analyzing/comparing variable info and variable descriptions, the following variables could change its type, in order to improve their description and decrease memory usage:\n",
    "\n",
    "1. Data format should be <b>integer</b> instead of <b>float</b>: <br>`DepTime`, `ArrTime`, `ActualElapsedTime`, `CRSElapsedTime`, `AirTime`, `ArrDelay`, `DepDelay `, `TaxiIn`, `TaxiOut`, `CarrierDelay`, `WeatherDelay`, `NASDelay`, `SecurityDelay `, `LateAircraftDelay`\n",
    "<br><br>\n",
    "2. Data format should be <b>category</b> instead of <b>object</b>:<br> `UniqueCarrier`, `TailNum`, `Origin`, `Dest`, `CancellationCode`\n",
    "\n",
    "\n",
    "\n",
    "The imported raw dataset has:\n",
    "- float64(14)\n",
    "- int64(10)\n",
    "- object(5)<br><br>\n",
    "After we apply the changes: \n",
    "- float64(0)\n",
    "- int64(24)\n",
    "- object(0)\n",
    "- category(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Analyze if we could improve the data formats in order to reduce its memory space\n",
    "\n",
    "- int64(24) --> uint8(0-24) or uint16(0-24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### 2.4. Clean\n",
    "\n",
    "#### 2.4.1. Correct the variable formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"source/all_data.db\")\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "def create_table():\n",
    "    c.execute('DROP TABLE IF EXISTS raw_data')\n",
    "    \n",
    "    sql_query = \"\"\"CREATE TABLE raw_data (Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                                          Year INTEGER,\n",
    "                                          Month INTEGER, \n",
    "                                          DayofMonth INTEGER,\n",
    "                                          DayOfWeek INTEGER, \n",
    "                                          DepTime INTEGER,\n",
    "                                          CRSDepTime INTEGER, \n",
    "                                          ArrTime INTEGER,\n",
    "                                          CRSArrTime INTEGER, \n",
    "                                          UniqueCarrier TEXT,\n",
    "                                          FlightNum INTEGER, \n",
    "                                          TailNum TEXT,\n",
    "                                          ActualElapsedTime INTEGER, \n",
    "                                          CRSElapsedTime INTEGER,\n",
    "                                          AirTime INTEGER, \n",
    "                                          ArrDelay INTEGER,\n",
    "                                          DepDelay INTEGER, \n",
    "                                          Origin TEXT,\n",
    "                                          Dest TEXT, \n",
    "                                          Distance INTEGER, \n",
    "                                          TaxiIn INTEGER,\n",
    "                                          TaxiOut INTEGER, \n",
    "                                          Cancelled INTEGER,\n",
    "                                          CancellationCode TEXT, \n",
    "                                          Diverted INTEGER,\n",
    "                                          CarrierDelay INTEGER, \n",
    "                                          WeatherDelay INTEGER,\n",
    "                                          NASDelay INTEGER, \n",
    "                                          SecurityDelay INTEGER,\n",
    "                                          LateAircraftDelay INTEGER)\"\"\"\n",
    "    c.execute(sql_query)\n",
    "    \n",
    "    c.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return print('Table created successfully')\n",
    "\n",
    "def raw_data_entry(start_year=1987,last_year=1988):\n",
    "    start_1 = time.time()\n",
    "    for years in range(0,last_year-start_year+1):\n",
    "        \n",
    "        start_2 = time.time()\n",
    "\n",
    "        for chunk in pd.read_csv('source/{}.csv'.format(start_year+years), chunksize=3000000,\n",
    "                                 encoding='latin-1'):\n",
    "            \n",
    "            float_columns = []\n",
    "            float_columns = (chunk.select_dtypes(['float'])).columns\n",
    "            \n",
    "            int_columns = []\n",
    "            int_columns = (chunk.select_dtypes(['int'])).columns\n",
    "\n",
    "            chunk.loc[:,float_columns] = chunk.loc[:,float_columns].fillna(0).astype(int)\n",
    "            chunk.loc[:,int_columns] = chunk.loc[:,int_columns].fillna(0)\n",
    "            \n",
    "            chunk.to_sql(name=\"raw_data\", con=conn, if_exists=\"append\", index=False)\n",
    "            print(chunk.iloc[0, 0])\n",
    "            \n",
    "            del chunk\n",
    "\n",
    "        end_2 = time.time()\n",
    "        print('time to include {}.csv:'.format(start_year+years),\n",
    "              '{:0.0f}'.format(end_2-start_2),'seconds')\n",
    "\n",
    "    end_1 = time.time()\n",
    "    print('total time:','{:0.0f}'.format((end_1-start_1)/60),'minutes')\n",
    "    \n",
    "    c.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return print('Values inserted successfully')\n",
    "    \n",
    "c.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"source/all_data.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987\n",
      "time to include 1987.csv: 17 seconds\n",
      "1988\n",
      "1988\n",
      "time to include 1988.csv: 62 seconds\n",
      "1989\n",
      "1989\n",
      "time to include 1989.csv: 66 seconds\n",
      "1990\n",
      "1990\n",
      "time to include 1990.csv: 68 seconds\n",
      "1991\n",
      "1991\n",
      "time to include 1991.csv: 62 seconds\n",
      "1992\n",
      "1992\n",
      "time to include 1992.csv: 65 seconds\n",
      "1993\n",
      "1993\n",
      "time to include 1993.csv: 63 seconds\n",
      "1994\n",
      "1994\n",
      "time to include 1994.csv: 65 seconds\n",
      "1995\n",
      "1995\n",
      "time to include 1995.csv: 67 seconds\n",
      "1996\n",
      "1996\n",
      "time to include 1996.csv: 67 seconds\n",
      "1997\n",
      "1997\n",
      "time to include 1997.csv: 66 seconds\n",
      "1998\n",
      "1998\n",
      "time to include 1998.csv: 67 seconds\n",
      "1999\n",
      "1999\n",
      "time to include 1999.csv: 69 seconds\n",
      "2000\n",
      "2000\n",
      "time to include 2000.csv: 71 seconds\n",
      "2001\n",
      "2001\n",
      "time to include 2001.csv: 76 seconds\n",
      "2002\n",
      "2002\n",
      "time to include 2002.csv: 66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3220: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "2003\n",
      "2003\n",
      "time to include 2003.csv: 90 seconds\n",
      "2004\n",
      "2004\n",
      "2004\n",
      "time to include 2004.csv: 96 seconds\n",
      "2005\n",
      "2005\n",
      "2005\n",
      "time to include 2005.csv: 122 seconds\n",
      "2006\n",
      "2006\n",
      "2006\n",
      "time to include 2006.csv: 97 seconds\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "time to include 2007.csv: 102 seconds\n",
      "2008\n",
      "2008\n",
      "2008\n",
      "time to include 2008.csv: 98 seconds\n",
      "total time: 27 minutes\n",
      "Values inserted successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"source/all_data.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "raw_data_entry(start_year,last_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 312 seconds\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"source/all_data.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "sql_query = \"\"\"CREATE TABLE IF NOT EXISTS data AS\n",
    "                                   SELECT Id,\n",
    "                                          Year, \n",
    "                                          Month, \n",
    "                                          DayofMonth, \n",
    "                                          FlightNum, \n",
    "                                          Distance, \n",
    "                                          UniqueCarrier, \n",
    "                                          TailNum, \n",
    "                                          Origin, \n",
    "                                          Dest\n",
    "                                     FROM raw_data;\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "c.execute(sql_query)\n",
    "\n",
    "end = time.time()\n",
    "print('total time:','{:0.0f}'.format(end-start),'seconds')\n",
    "\n",
    "c.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"source/all_data.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "sql_query = \"\"\"ALTER TABLE data \n",
    "                ADD COLUMN Date datetime;\"\"\"\n",
    "\n",
    "c.execute(sql_query)\n",
    "\n",
    "c.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"source/all_data.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "sql_query = \"\"\"UPDATE data \n",
    "                  SET Date = Year || '-' || Month || '-' || DayofMonth\"\"\"\n",
    "\n",
    "c.execute(sql_query)\n",
    "conn.commit()\n",
    "\n",
    "c.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"source/all_data.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "sql_query = \"\"\"SELECT Id,\n",
    "                      Date,\n",
    "                      Origin, \n",
    "                      Dest,\n",
    "                      FlightNum, \n",
    "                      Distance, \n",
    "                      UniqueCarrier, \n",
    "                      TailNum\n",
    "                 FROM data\n",
    "                WHERE Date <= 1988-01-01\n",
    "                LIMIT 10;\"\"\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for chunk in pd.read_sql_query(sql_query, conn, chunksize=100000):\n",
    "    \n",
    "    df = pd.concat([df,chunk], ignore_index=True, sort=False)\n",
    "    \n",
    "    df.loc[:,'Date'] = pd.to_datetime(df.loc[:,'Date'])\n",
    "        \n",
    "    df.loc[:,'UniqueCarrier'] = df.loc[:,'UniqueCarrier'].astype('category')\n",
    "    df.loc[:,'TailNum'] = df.loc[:,'TailNum'].astype('category')\n",
    "    df.loc[:,'Origin'] = df.loc[:,'Origin'].astype('category')\n",
    "    df.loc[:,'Dest'] = df.loc[:,'Dest'].astype('category')   \n",
    "    \n",
    "    df.loc[:,'FlightNum'] = df.loc[:,'FlightNum'].astype(np.int16)\n",
    "    df.loc[:,'Distance'] = df.loc[:,'Distance'].astype(np.int16)\n",
    "    \n",
    "    print(chunk.iloc[0,1][:4],'-',df.shape[0]/1000000,'M rows')\n",
    "\n",
    "del chunk\n",
    "c.close()\n",
    "conn.close()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('import to DataFrame:','{:0.0f}'.format(end-start),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>Distance</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987-10-14</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1451</td>\n",
       "      <td>447</td>\n",
       "      <td>PS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1987-10-15</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1451</td>\n",
       "      <td>447</td>\n",
       "      <td>PS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1987-10-17</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1451</td>\n",
       "      <td>447</td>\n",
       "      <td>PS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-10-18</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1451</td>\n",
       "      <td>447</td>\n",
       "      <td>PS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1987-10-19</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1451</td>\n",
       "      <td>447</td>\n",
       "      <td>PS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id       Date Origin Dest  FlightNum  Distance UniqueCarrier TailNum\n",
       "0   1 1987-10-14    SAN  SFO       1451       447            PS       0\n",
       "1   2 1987-10-15    SAN  SFO       1451       447            PS       0\n",
       "2   3 1987-10-17    SAN  SFO       1451       447            PS       0\n",
       "3   4 1987-10-18    SAN  SFO       1451       447            PS       0\n",
       "4   5 1987-10-19    SAN  SFO       1451       447            PS       0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 8 columns):\n",
      "Id               10 non-null int64\n",
      "Date             10 non-null datetime64[ns]\n",
      "Origin           10 non-null category\n",
      "Dest             10 non-null category\n",
      "FlightNum        10 non-null int16\n",
      "Distance         10 non-null int16\n",
      "UniqueCarrier    10 non-null category\n",
      "TailNum          10 non-null category\n",
      "dtypes: category(4), datetime64[ns](1), int16(2), int64(1)\n",
      "memory usage: 672.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To avoid working with unnecessary data, we'll choose the followings:\n",
    "cols = ['Year',\n",
    "        'Month',\n",
    "        'DayofMonth',\n",
    "        'UniqueCarrier',\n",
    "        'FlightNum',\n",
    "        'TailNum',\n",
    "        'Origin',\n",
    "        'Dest',\n",
    "        'Distance']\n",
    "\n",
    "# Init df as DataFrame\n",
    "df_load = pd.DataFrame({'UniqueCarrier': list(),\n",
    "                        'TailNum': list(),\n",
    "                        'Origin': list(),\n",
    "                        'Dest': list()}, \n",
    "                        dtype='category')\n",
    "\n",
    "df = pd.DataFrame({'UniqueCarrier': list(),\n",
    "                   'TailNum': list(),\n",
    "                   'Origin': list(),\n",
    "                   'Dest': list()}, \n",
    "                   dtype='category')\n",
    "\n",
    "# Import DataFrames (two by two to avoid memory overflow) with optimized column types\n",
    "i=0\n",
    "\n",
    "start_1 = time.time()\n",
    "\n",
    "for years in range(0,last_year-start_year+1):\n",
    "\n",
    "    df_load = pd.read_csv('source/{}.csv'.format(start_year+years),\n",
    "                          dtype = {'Year':np.float16,\n",
    "                                   'Month':np.float16,\n",
    "                                   'DayofMonth':np.float16,\n",
    "                                   'UniqueCarrier':'category',\n",
    "                                   'FlightNum':np.float16,\n",
    "                                   'TailNum':'category',\n",
    "                                   'Origin':'category',\n",
    "                                   'Dest':'category',\n",
    "                                   'Distance':np.float16},\n",
    "                          usecols = cols,\n",
    "                          na_values = ['Year',\n",
    "                                       'Month',\n",
    "                                       'DayofMonth',\n",
    "                                       'UniqueCarrier',\n",
    "                                       'FlightNum',\n",
    "                                       'TailNum',\n",
    "                                       'Origin',\n",
    "                                       'Dest',\n",
    "                                       'Distance',\n",
    "                                        np.nan,\n",
    "                                        None,\n",
    "                                       'NaN',\n",
    "                                       '000000',\n",
    "                                       'OO'],\n",
    "                          encoding='latin-1')\n",
    "    \n",
    "    uc_UniqueCarrier = union_categoricals([df_load.loc[:,'UniqueCarrier'],df.loc[:,'UniqueCarrier']])\n",
    "    uc_TailNum = union_categoricals([df_load.loc[:,'TailNum'],df.loc[:,'TailNum']])\n",
    "    uc_Origin = union_categoricals([df_load.loc[:,'Origin'],df.loc[:,'Origin']])\n",
    "    uc_Dest = union_categoricals([df_load.loc[:,'Dest'],df.loc[:,'Dest']])\n",
    "    \n",
    "    df_load.loc[:,'UniqueCarrier'] = pd.Categorical(df_load.loc[:,'UniqueCarrier'],categories=uc_UniqueCarrier.categories)\n",
    "    df_load.loc[:,'TailNum'] = pd.Categorical(df_load.loc[:,'TailNum'],categories=uc_TailNum.categories)\n",
    "    df_load.loc[:,'Origin'] = pd.Categorical(df_load.loc[:,'Origin'],categories=uc_Origin.categories )\n",
    "    df_load.loc[:,'Dest'] = pd.Categorical(df_load.loc[:,'Dest'],categories=uc_Dest.categories )\n",
    "    \n",
    "    df.loc[:,'UniqueCarrier'] = pd.Categorical(df.loc[:,'UniqueCarrier'],categories=uc_UniqueCarrier.categories )\n",
    "    df.loc[:,'TailNum'] = pd.Categorical(df.loc[:,'TailNum'], categories=uc_TailNum.categories )\n",
    "    df.loc[:,'Origin'] = pd.Categorical(df.loc[:,'Origin'], categories=uc_Origin.categories )\n",
    "    df.loc[:,'Dest'] = pd.Categorical(df.loc[:,'Dest'], categories=uc_Dest.categories )\n",
    "    \n",
    "    df = pd.concat([df,df_load], ignore_index=True, sort=False)\n",
    "    \n",
    "    del df_load\n",
    "    \n",
    "    df.loc[:,'Year'].fillna(value=0, inplace=True)\n",
    "    df.loc[:,'Month'].fillna(value=0, inplace=True)\n",
    "    df.loc[:,'DayofMonth'].fillna(value=0, inplace=True)\n",
    "    df.loc[:,'FlightNum'].fillna(value=0, inplace=True)\n",
    "    df.loc[:,'Distance'].fillna(value=0, inplace=True)\n",
    "    \n",
    "    df.loc[:,'Year'] = df.loc[:,'Year'].astype(np.int16)\n",
    "    df.loc[:,'Month'] = df.loc[:,'Month'].astype(np.int8)\n",
    "    df.loc[:,'DayofMonth'] = df.loc[:,'DayofMonth'].astype(np.int8)\n",
    "    df.loc[:,'FlightNum'] = df.loc[:,'FlightNum'].astype(np.int16)\n",
    "    df.loc[:,'Distance'] = df.loc[:,'Distance'].astype(np.int16)\n",
    "    \n",
    "    print(start_year+years)\n",
    "print('done')\n",
    "end_1 = time.time()\n",
    "print(end_1-start_1,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10000.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_list = []\n",
    "\n",
    "for row in range(0,df_10000.shape[0]):\n",
    "    df_10000.loc[row,'Date'] = datetime(year=df_10000.loc[row,'Year'],\n",
    "                                      month=df_10000.loc[row,'Month'],\n",
    "                                      day=df_10000.loc[row,'DayofMonth'])\n",
    "    \n",
    "df_10000.drop(columns=['Year','Month','DayofMonth'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10000.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_10000.loc[:,'Origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_san_sfo = df_10000.loc[(df_10000['Origin']=='SAN')|(df_10000['Origin']=='SFO')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctdf = (df_san_sfo.reset_index()\n",
    "          .groupby(['Date','Origin'], as_index=False)\n",
    "          .count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctdf = (df_san_sfo.reset_index().groupby(['Date','Origin'],as_index=False).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# key gives the group name (i.e. category), data gives the actual values\n",
    "for key, data in ctdf.groupby('Origin'):\n",
    "    data.plot(x='Date', y='Dest', ax=ax, label=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "df_10000.groupby(by=['Origin','Date']).count()['Dest'].plot(label='Retweets', color = 'crimson')\n",
    "# df.favorite_count.plot(label='Favorites', color = 'teal')\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('Tweet timestamp')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper left')\n",
    "ax.grid(axis='x')\n",
    "\n",
    "# Plot title\n",
    "plt.title('Favorites and retweets over the time')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10000['Origin'].value_counts(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10000['Origin'].value_counts(ascending=False)[0:10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10000.loc[df_10000['Origin']==x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_10000['Origin'].value_counts(ascending=False)[0:10].index\n",
    "y = df_10000['Origin'].value_counts(ascending=False)[0:10]\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot the total crashes\n",
    "ax = sb.barplot(x=x, y=y, data=df_10000, color=sb.set_palette(\"YlOrRd_r\", 10))\n",
    "\n",
    "# # Add a legend and informative axis label\n",
    "# ax.set(xlim=(0, 150), ylabel=\"Dog Breed\",title='Top 10 Most Rated Dog Breed',\n",
    "#        xlabel=\"Count of Dog Breed\")\n",
    "\n",
    "# for ax in plt.gcf().axes:\n",
    "#     l = ax.get_title()\n",
    "#     ax.set_title(l, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes = []\n",
    "\n",
    "# To avoid working with unnecessary data, we'll drop every column unless the followings:\n",
    "cols_of_interest = ['Year',\n",
    "                    'Month',\n",
    "                    'DayofMonth',\n",
    "                    'DayOfWeek',\n",
    "                    'UniqueCarrier',\n",
    "                    'FlightNum',\n",
    "                    'TailNum',\n",
    "                    'Origin',\n",
    "                    'Dest',\n",
    "                    'Distance']\n",
    "\n",
    "# List of variables with object type\n",
    "list_of_obj = ['UniqueCarrier',\n",
    "               'TailNum',\n",
    "               'Origin',\n",
    "               'Dest']\n",
    "\n",
    "# List of variables with int type\n",
    "list_of_int = ['Year',\n",
    "               'Month',\n",
    "               'DayofMonth',\n",
    "               'DayOfWeek',\n",
    "               'FlightNum',\n",
    "               'Distance']\n",
    "\n",
    "missing_values = [\"n/a\", \"na\", \"--\",'na','NA']\n",
    "\n",
    "# Init df as DataFrame\n",
    "df = pd.DataFrame()\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "# Get optimized column types of the DataFrame as dictionary\n",
    "column_types = get_column_types(df, cols_of_interest)\n",
    "\n",
    "for years in range(0,len(year_list)):\n",
    "    print(year_list[years])\n",
    "    print(years)\n",
    "\n",
    "    # Import DataFrames (two by two to avoid memory overflow) with optimized column types\n",
    "    df_first = pd.read_csv('source/{}.csv'.format(year_list[years][0]), nrows=1000,\n",
    "                           usecols = cols_of_interest, dtype=column_types,\n",
    "                           encoding='latin-1', na_values = missing_values)\n",
    "    \n",
    "    df_last = pd.read_csv('source/{}.csv'.format(year_list[years][1]), nrows=1000,\n",
    "                           usecols = cols_of_interest, dtype=column_types,\n",
    "                          encoding='latin-1', na_values = missing_values)\n",
    "    \n",
    "    df = pd.concat([df_first,df_last], ignore_index=True)\n",
    "    print(df[list_of_int].info())\n",
    "    \n",
    "    df[list_of_int].fillna(-1, inplace=True)\n",
    "    df[list_of_int].astype(int, inplace=True)\n",
    "    df[list_of_int].astype(str, inplace=True)\n",
    "    df[list_of_int].replace('-1', np.nan, inplace=True)\n",
    "    \n",
    "    #df.loc[:,list_of_obj] = df.loc[:,list_of_obj].astype('category')\n",
    "    \n",
    "    #df.select_dtypes(include=['int']).fillna(value=0,inplace=True)\n",
    "    #df.loc[:,'UniqueCarrier'].cat.add_categories(0).fillna(value=0,inplace=True)\n",
    "    #df.loc[:,'TailNum'].cat.add_categories(0).fillna(value=0,inplace=True)\n",
    "    #df.loc[:,'Origin'].cat.add_categories(0).fillna(value=0,inplace=True)\n",
    "    #df.loc[:,'Dest'].cat.add_categories(0).fillna(value=0,inplace=True)\n",
    "    \n",
    "    # Concatenate both DataFrames\n",
    "    list_of_dataframes.append(df)\n",
    "    \n",
    "    # Delete temporary DataFrames to free memory\n",
    "    del df_first, df_last\n",
    "    \n",
    "    list_of_dataframes[years].loc[:,list_of_obj] = list_of_dataframes[years].loc[:,list_of_obj].astype('category')\n",
    "\n",
    "df_total = pd.concat(list_of_dataframes, axis = 0, ignore_index=True)\n",
    "\n",
    "del list_of_dataframes\n",
    "\n",
    "df_total.loc[:,list_of_obj] = df_total.loc[:,list_of_obj].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[cols_of_interest].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid working with unnecessary data, we'll drop every column unless the followings:\n",
    "cols_of_interest = ['Year',\n",
    "                    'Month',\n",
    "                    'DayofMonth',\n",
    "                    'DayOfWeek',\n",
    "                    'UniqueCarrier',\n",
    "                    'FlightNum',\n",
    "                    'TailNum',\n",
    "                    'Origin',\n",
    "                    'Dest',\n",
    "                    'Distance']\n",
    "\n",
    "# List of variables with object type\n",
    "list_of_obj = ['UniqueCarrier',\n",
    "               'TailNum',\n",
    "               'Origin',\n",
    "               'Dest']\n",
    "\n",
    "# Init df as DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Get optimized column types of the DataFrame as dictionary\n",
    "column_types = get_column_types(df, cols_of_interest)\n",
    "\n",
    "if (last_year-start_year)%2==0:\n",
    "    print('par')\n",
    "    print('')\n",
    "    for year in range(start_year,last_year+1,2):\n",
    "        print('first year',year-1)\n",
    "        print('second year',year)\n",
    "        print('')\n",
    "        \n",
    "        # Import DataFrames (two by two to avoid memory overflow) with optimized column types\n",
    "        df_first = pd.read_csv('source/{}.csv'.format(year-1), usecols = cols_of_interest, dtype=column_types, nrows=20,encoding='latin-1')\n",
    "        df_last = pd.read_csv('source/{}.csv'.format(year), usecols = cols_of_interest, dtype=column_types, nrows=20,encoding='latin-1')\n",
    "        \n",
    "    # Concatenate both DataFrames\n",
    "    df = pd.concat([df_first,df_last], axis=0)\n",
    "\n",
    "    # Delete temporary DataFrames to free memory\n",
    "    del df_first, df_last\n",
    "\n",
    "    # When concatenating two DataFrames where one has a categorical column\n",
    "    # that the other is missing, the result contains the categorical column \n",
    "    # as a 'object' (losing the \"real\" dtype).\n",
    "    # These situation is documentated as a bug (https://github.com/pandas-dev/pandas/issues/25412).\n",
    "    # To get around this situation we need to transform its datatypes two times (before and after concat)\n",
    "\n",
    "    df.loc[:,list_of_obj] = df.loc[:,list_of_obj].astype('category')\n",
    "else:\n",
    "    print('impar')\n",
    "    print('')\n",
    "    for year in range(start_year+1,last_year+1,2):\n",
    "        print('first year',year-1)\n",
    "        print('second year',year)\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid working with unnecessary data, we'll drop every column unless the followings:\n",
    "cols_of_interest = ['Year',\n",
    "                    'Month',\n",
    "                    'DayofMonth',\n",
    "                    'DayOfWeek',\n",
    "                    'UniqueCarrier',\n",
    "                    'FlightNum',\n",
    "                    'TailNum',\n",
    "                    'Origin',\n",
    "                    'Dest',\n",
    "                    'Distance']\n",
    "\n",
    "# List of variables with object type\n",
    "list_of_obj = ['UniqueCarrier',\n",
    "               'TailNum',\n",
    "               'Origin',\n",
    "               'Dest']\n",
    "\n",
    "# Init df as DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Get optimized column types of the DataFrame as dictionary\n",
    "column_types = get_column_types(df, cols_of_interest)\n",
    "\n",
    "# Import DataFrames (two by two to avoid memory overflow) with optimized column types\n",
    "df_2008 = pd.read_csv('source/2008.csv', usecols = cols_of_interest, dtype=column_types)\n",
    "df_2007 = pd.read_csv('source/2007.csv', usecols = cols_of_interest, dtype=column_types)\n",
    "\n",
    "# Concatenate both DataFrames\n",
    "df = df_2007.append(df_2008, ignore_index=True)\n",
    "\n",
    "# Delete temporary DataFrames to free memory\n",
    "del df_2007, df_2008\n",
    "\n",
    "# When concatenating two DataFrames where one has a categorical column\n",
    "# that the other is missing, the result contains the categorical column \n",
    "# as a 'object' (losing the \"real\" dtype).\n",
    "# These situation is documentated as a bug (https://github.com/pandas-dev/pandas/issues/25412).\n",
    "# To get around this situation we need to transform its datatypes two times (before and after concat)\n",
    "\n",
    "df.loc[:,list_of_obj] = df.loc[:,list_of_obj].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = ['Year',\n",
    "                    'Month',\n",
    "                    'DayofMonth',\n",
    "                    'DayOfWeek',\n",
    "                    'UniqueCarrier',\n",
    "                    'FlightNum',\n",
    "                    'TailNum',\n",
    "                    'Origin',\n",
    "                    'Dest',\n",
    "                    'Distance']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "column_types = get_column_types(df, cols_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008 = pd.read_csv('source/2008.csv', usecols = cols_of_interest, keep_default_na=False, na_values=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008 = df_2008.astype(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2007 = pd.read_csv('source/2007.csv', usecols = cols_of_interest, keep_default_na=False, na_values=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2007 = df_2007.astype(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_2007,df_2008], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008 = pd.read_csv('source/2008.csv', usecols = cols_of_interest, dtype=column_types)\n",
    "df_2007 = pd.read_csv('source/2007.csv', usecols = cols_of_interest, dtype=column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2008 = pd.Categorical(df_2008.select_dtypes(include=['float'])).fillna(0)\n",
    "\n",
    "df_2008.apply(pd.Categorical.fillna(value=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2008.loc[:,cols_of_interest].fillna(0, inplace=True)\n",
    "df_2008 = df_2008.select_dtypes(include=['category']).add_categories(0).fillna(0)\n",
    "df_2007 = df_2007.select_dtypes(include=['category']).add_categories(0).fillna(0)\n",
    "\n",
    "\n",
    "#df_2007.loc[:,cols_of_interest].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_2007,df_2008], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2007.loc[:,'TailNum'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2007.loc[:,'TailNum'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to be calculating memory usage a lot,\n",
    "# so we'll create a function to save us some time!\n",
    "def mem_usage(pandas_obj):\n",
    "    \n",
    "    usage_mb = 0\n",
    "    \n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        \n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "        \n",
    "    else: # we assume if not a df it's a series\n",
    "        \n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "        usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "        \n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which variable we want to change format from float to int\n",
    "list_float_to_int = ['DepTime', \n",
    "                     'ArrTime', \n",
    "                     'ActualElapsedTime',\n",
    "                     'CRSElapsedTime', \n",
    "                     'AirTime', \n",
    "                     'ArrDelay', \n",
    "                     'DepDelay', \n",
    "                     'TaxiIn', \n",
    "                     'TaxiOut', \n",
    "                     'CarrierDelay', \n",
    "                     'WeatherDelay', \n",
    "                     'NASDelay', \n",
    "                     'SecurityDelay', \n",
    "                     'LateAircraftDelay']\n",
    "\n",
    "\n",
    "\n",
    "# Cast during the csv read\n",
    "df_float_to_int = pd.read_csv('source/2008.csv', nrows=5, dtype={'DepTime': np.int8,\n",
    "                                                          'ArrTime': np.int8,\n",
    "                                                          'ActualElapsedTime': np.int8,\n",
    "                                                          'CRSElapsedTime': np.int8,\n",
    "                                                          'AirTime': np.int8,\n",
    "                                                          'ArrDelay': np.int8,\n",
    "                                                          'DepDelay': np.int8,\n",
    "                                                          'TaxiIn': np.int8,\n",
    "                                                          'TaxiOut': np.int8,\n",
    "                                                          'CarrierDelay': np.int8,\n",
    "                                                          'WeatherDelay': np.int8,\n",
    "                                                          'NASDelay': np.int8,\n",
    "                                                          'SecurityDelay': np.int8,\n",
    "                                                          'LateAircraftDelay': np.int8\n",
    "                                                         })  \n",
    "\n",
    "#df_float = pd.read_csv('source/2008.csv', usecols=list_float_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float.loc[:,list_float_to_int].replace(np.NaN, '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float.loc[:,list_float_to_int].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,list_float_to_int].replace(np.NaN, '', inplace=True)\n",
    "\n",
    "df.loc[:,list_float_to_int].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['float']).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_float_to_int = ['DepTime', \n",
    "                     'ArrTime', \n",
    "                     'ActualElapsedTime',\n",
    "                     'CRSElapsedTime', \n",
    "                     'AirTime', \n",
    "                     'ArrDelay', \n",
    "                     'DepDelay', \n",
    "                     'TaxiIn', \n",
    "                     'TaxiOut', \n",
    "                     'CarrierDelay', \n",
    "                     'WeatherDelay', \n",
    "                     'NASDelay', \n",
    "                     'SecurityDelay', \n",
    "                     'LateAircraftDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chunk in pd.read_csv('source/2008.csv', chunksize=10000):\n",
    "    #chunk.apply(pd.to_numeric, errors='coerce')\n",
    "       \n",
    "    chunk_float_to_int = chunk.select_dtypes(include=['float']).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "list_deptime = pd.concat(list_deptime, axis = 0)\n",
    "list_arrtime = pd.concat(list_arrtime, axis = 0)\n",
    "#chunk_1 = pd.concat([chunk])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_arrtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_deptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list_deptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('source/2008.csv', nrows=20)\n",
    "\n",
    "df_float_to_int = df_test.select_dtypes(include=['float']).fillna(0).astype(int)\n",
    "df_obj_to_cat = df_test.select_dtypes(include=['object']).fillna(0).astype('category')\n",
    "\n",
    "# create the dict of index names and optimized datatypes\n",
    "dtypes = df_test.dtypes\n",
    "\n",
    "colnames = dtypes.index\n",
    "types = [i.name for i in dtypes.values]\n",
    "\n",
    "column_types = dict(zip(colnames, types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_optimized = pd.read_csv('source/2008.csv', nrows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in pd.read_csv('source/2008.csv', chunksize=10000):\n",
    "    chunk.apply(pd.to_numeric, errors='coerce')\n",
    "       \n",
    "    chunk_float_to_int = chunk.select_dtypes(include=['float']).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each csv file has aproximatelly 600 MB of file size, and it all together represents 12,0 GB.\n",
    "\n",
    "    \n",
    "In a ideal world, a normal workspace could handle all these files at the same time, but for example my computer have only 8 GB of RAM\n",
    "\n",
    "\n",
    "s we're dealing with large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in ['float','int','object']:\n",
    "    selected_dtype = df.select_dtypes(include=[dtype])\n",
    "    mean_usage_b = selected_dtype.memory_usage(deep=True).mean()\n",
    "    mean_usage_mb = mean_usage_b / 1024 ** 2\n",
    "    print(\"Average memory usage for {} columns: {:03.2f}MB\".format(dtype,mean_usage_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to be calculating memory usage a lot,\n",
    "# so we'll create a function to save us some time!\n",
    "def mem_usage(pandas_obj):\n",
    "    \n",
    "    usage_mb = 0\n",
    "    \n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        \n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "        \n",
    "    else: # we assume if not a df it's a series\n",
    "        \n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "        usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "        \n",
    "    return \"{:03.2f} MB\".format(usage_mb)\n",
    "\n",
    "df_int = df.select_dtypes(include=['int'])\n",
    "converted_int = df_int.apply(pd.to_numeric,downcast='unsigned')\n",
    "print(mem_usage(df_int))\n",
    "print(mem_usage(converted_int))\n",
    "compare_ints = pd.concat([df_int.dtypes,converted_int.dtypes],axis=1)\n",
    "compare_ints.columns = ['before','after']\n",
    "compare_ints.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float = df.select_dtypes(include=['float'])\n",
    "converted_float = df_float.apply(pd.to_numeric,downcast='float')\n",
    "print(mem_usage(df_float))\n",
    "print(mem_usage(converted_float))\n",
    "compare_floats = pd.concat([df_float.dtypes,converted_float.dtypes],axis=1)\n",
    "compare_floats.columns = ['before','after']\n",
    "compare_floats.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### 2.3. Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_list = glob.glob('source/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_list[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(f, encoding='latin-1') for f in download_list[:-1]], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time of execution\n",
    "#start_3 = time.time()\n",
    "\n",
    "#data = pd.read_csv(filepath[:-4])\n",
    "\n",
    "# Calculate the time of execution\n",
    "#end_3 = time.time()\n",
    "\n",
    "#print('read df - execution time: ',end_3 - start_3, 'seconds')\n",
    "#print('read df - execution time: ',(end_3 - start_3)/60, 'minutes')\n",
    "#print('-----------------------------------------------------')\n",
    "#print('total execution time: ',(end_1+end_2+end_3)-(start_1+start_2+start_3), 'seconds')\n",
    "#print('total execution time: ',((end_1+end_2+end_3)-(start_1+start_2+start_3))/60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of your dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### What is/are the main feature(s) of interest in your dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration\n",
    "\n",
    "> In this section, investigate distributions of individual variables. If\n",
    "you see unusual points or outliers, take a deeper look to clean things up\n",
    "and prepare yourself to look at relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make sure that, after every plot or related series of plots, that you\n",
    "include a Markdown cell with comments about what you observed, and what\n",
    "you plan on investigating next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration\n",
    "\n",
    "> In this section, investigate relationships between pairs of variables in your\n",
    "data. Make sure the variables that you cover here have been introduced in some\n",
    "fashion in the previous section (univariate exploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration\n",
    "\n",
    "> Create plots of three or more variables to investigate your data even\n",
    "further. Make sure that your investigations are justified, and follow from\n",
    "your work in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the end of your report, make sure that you export the notebook as an\n",
    "html file from the `File > Download as... > HTML` menu. Make sure you keep\n",
    "track of where the exported file goes, so you can put it in the same folder\n",
    "as this notebook for project submission. Also, make sure you remove all of\n",
    "the quote-formatted guide notes like this one before you finish your report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
